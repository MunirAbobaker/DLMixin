{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load zip file and unzi it\n",
    "import zipfile\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def unzip(zip_file, dest_dir):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_dir)\n",
    "\n",
    "unzip('./data/archive.zip', './data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete zip file\n",
    "os.remove('./data/archive.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:22:25] </span>PrettyLogger is now active. All error messages will be displayed with rich            <a href=\"file://C:\\Users\\D073999\\Documents\\Personal\\MachineLearningPath\\FromZeroToHero\\PrettyLogger.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">PrettyLogger.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\D073999\\Documents\\Personal\\MachineLearningPath\\FromZeroToHero\\PrettyLogger.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>formatting.                                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:22:25]\u001b[0m\u001b[2;36m \u001b[0mPrettyLogger is now active. All error messages will be displayed with rich            \u001b]8;id=840990;file://C:\\Users\\D073999\\Documents\\Personal\\MachineLearningPath\\FromZeroToHero\\PrettyLogger.py\u001b\\\u001b[2mPrettyLogger.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=628184;file://C:\\Users\\D073999\\Documents\\Personal\\MachineLearningPath\\FromZeroToHero\\PrettyLogger.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0mformatting.                                                                           \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../../PrettyLogger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load csv files using pandas\n",
    "real_news = pd.read_csv('./data/True.csv')\n",
    "fake_news = pd.read_csv('./data/Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes\n",
    "real_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "news = pd.concat([real_news, fake_news])\n",
    "\n",
    "# shuffle the data\n",
    "news_df = news.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARTHA STEWART Makes Lewd Gesture Towards Trum...</td>\n",
       "      <td>Martha, Martha, Martha You re 75-years old! Ti...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 8, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lebanon's Hariri says to hold off resignation ...</td>\n",
       "      <td>BEIRUT (Reuters) - Lebanon s Saad al-Hariri sa...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burundi takes steps to extend president's rule...</td>\n",
       "      <td>NAIROBI (Reuters) - Burundi s cabinet backed a...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 27, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REVEALED: The Establishment’s Scheme to Take D...</td>\n",
       "      <td>21st Century Wire says Based on the events we ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cutting Pentagon's acquisition chief post may ...</td>\n",
       "      <td>WASHINGTON (Reuters) - A proposal by a U.S. Se...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 17, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  MARTHA STEWART Makes Lewd Gesture Towards Trum...   \n",
       "1  Lebanon's Hariri says to hold off resignation ...   \n",
       "2  Burundi takes steps to extend president's rule...   \n",
       "3  REVEALED: The Establishment’s Scheme to Take D...   \n",
       "4  Cutting Pentagon's acquisition chief post may ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Martha, Martha, Martha You re 75-years old! Ti...      politics   \n",
       "1  BEIRUT (Reuters) - Lebanon s Saad al-Hariri sa...     worldnews   \n",
       "2  NAIROBI (Reuters) - Burundi s cabinet backed a...     worldnews   \n",
       "3  21st Century Wire says Based on the events we ...   Middle-east   \n",
       "4  WASHINGTON (Reuters) - A proposal by a U.S. Se...  politicsNews   \n",
       "\n",
       "                 date  label  \n",
       "0         May 8, 2017      0  \n",
       "1  November 22, 2017       1  \n",
       "2   October 27, 2017       1  \n",
       "3    January 14, 2017      0  \n",
       "4       May 17, 2016       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "news_df.to_csv('./data/news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('./data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(news_df, test_size=0.4, random_state=42)\n",
    "# split the test set into validation and test set\n",
    "validation, test = train_test_split(test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the vocabulary\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def get_vocab(data):\n",
    "    count = Counter()\n",
    "    for text in data:\n",
    "        count.update(text.split())\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocab(train['text']+train['title']+train['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word: i+2 for i, (word, count) in enumerate(vocab.items()) if count > 1}\n",
    "vocab['<unk>'] = 0\n",
    "vocab['<pad>'] = 1\n",
    "\n",
    "# save the vocab\n",
    "import json\n",
    "with open('./data/vocab.json', 'w') as f:\n",
    "    json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161558"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3535, 6811]\n",
      "Decoded text: <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> example text\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text'] + \" \" + self.data.iloc[idx]['title']\n",
    "        text = self.tokenizer(text, self.vocab)\n",
    "        encoded_text = self.encode_text(text, self.vocab)\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return {'text': torch.tensor(encoded_text), 'label': torch.tensor(label)}\n",
    "\n",
    "    def tokenizer(self, text, vocab):\n",
    "        return [vocab.get(token, vocab['<unk>']) for token in text.split()]\n",
    "\n",
    "    def encode_text(self, text, vocab):\n",
    "        # Ensure the encoded text does not exceed the vocab size\n",
    "        encoded = [vocab['<pad>']] * (50 - len(text)) + text[:50]\n",
    "        return [min(idx, len(vocab) - 1) for idx in encoded]\n",
    "\n",
    "    def decode_text(self, text, vocab):\n",
    "        return ' '.join([self.inverse_vocab.get(i, '<unk>') for i in text])\n",
    "\n",
    "dataset = NewsDataset(train, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example to check encoding and decoding\n",
    "sample_text = \"example text\"\n",
    "encoded = dataset.tokenizer(sample_text, vocab)\n",
    "encoded_text = dataset.encode_text(encoded, vocab)\n",
    "decoded_text = dataset.decode_text(encoded_text, vocab)\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(train, vocab)\n",
    "validation_dataset = NewsDataset(validation, vocab)\n",
    "test_dataset = NewsDataset(test, vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 161559)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161540"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxi = -100\n",
    "for batch in train_loader:\n",
    "    text = batch['text']\n",
    "    min_val = torch.min(text).item()\n",
    "    max_val = torch.max(text).item()\n",
    "    if max_val > maxi:\n",
    "        maxi = max_val\n",
    "    #print(f\"Min value in text: {min_val}, Max value in text: {max_val}\")\n",
    "maxi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropouts):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.Lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropouts, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropouts)\n",
    "\n",
    "    def forward(self, text):\n",
    "        if torch.max(text) >= self.embedding.num_embeddings or torch.min(text) < 0:\n",
    "            raise ValueError(\"Index out of range in the embedding layer\")\n",
    "        embedded = self.embedding(text) #self.dropout(self.embedding(text))\n",
    "        output, (hidden, cell) = self.Lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da55281c82cc4090a096f7a6e21dffbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.32235894735123866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda50cb4f318412fad694972d7047273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.0504358345261087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ff7aaab62d4b0a8b0b77914282ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.016859171517858904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294f3093dd5a437abc59b5a35c457868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.0021806743409445357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaab94a5c6643b5806cbb71c6121320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.0016879530658396823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d36a44215441d48979f288cfbb603f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training loop\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = \"cpu\" #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = len(vocab)  #161559 #\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "dropouts = 0.5\n",
    "\n",
    "model = NewsLSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropouts).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "def train_epoch(model, titerator, viterator, epochs, optimizer, criterion, device):\n",
    "    # total loss\n",
    "    total_tloss, total_vloss, tlossi, vlossi = 0.0, 0.0, [], []\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoc_loss = 0\n",
    "        for batch in tqdm.tqdm(titerator):\n",
    "            text = batch['text'].to(device)\n",
    "            label = batch['label'].to(device).float()\n",
    "            #print(f\"Max index in batch: {torch.max(text)}, Min index in batch: {torch.min(text)}\")\n",
    "            if torch.max(text) >= model.embedding.num_embeddings:\n",
    "                print(f\"Out-of-range index found in input: {torch.max(text)}\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(text).squeeze(1)\n",
    "            loss = criterion(output, label)\n",
    "            tlossi.append(loss.item())\n",
    "            total_tloss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoc_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1} loss: {epoc_loss/len(titerator)}')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in viterator:\n",
    "                text = batch['text'].to(device)\n",
    "                label = batch['label'].to(device).float()\n",
    "                output = model(text).squeeze(1)\n",
    "                loss = criterion(output, label)\n",
    "                vlossi.append(loss.item())\n",
    "                total_vloss += loss.item()\n",
    "    return total_tloss/len(titerator), total_vloss/len(viterator), tlossi, vlossi\n",
    "\n",
    "total_tloss, total_vloss, tlossi, vlossi = train_epoch(model, train_loader, validation_loader, 10, optimizer, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(tloss, vloss):\n",
    "    plt.plot(tloss, label=\"Training loss\")\n",
    "    plt.plot(vloss, label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(tlossi, vlossi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
